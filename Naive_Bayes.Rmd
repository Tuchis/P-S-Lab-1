---
editor_options:
  markdown:
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Probability and Statistics

# Lab Assignment 1: Naive Bayes Classifier

### *Andrii Pletinka, Vladyslav Hymennyy, Olena Sniatynska*

## Introduction

During the past three weeks, we learned a couple of essential notions
and theorems, and one of the most important among them is the *Bayes
theorem*.

One of its applications is **Naive Bayes classifier**, which is a
probabilistic classifier whose aim is to determine which class some
observation probably belongs to by using the Bayes formula:
$$\mathsf{P}(\mathrm{class}\mid \mathrm{observation})=\frac{\mathsf{P}(\mathrm{observation}\mid\mathrm{class})\mathsf{P}(\mathrm{class})}{\mathsf{P}(\mathrm{observation})}$$

Under the strong independence assumption, one can calculate
$\mathsf{P}(\mathrm{observation} \mid \mathrm{class})$ as
$$\mathsf{P}(\mathrm{observation}) = \prod_{i=1}^{n} \mathsf{P}(\mathrm{feature}_i), \qquad \mathsf{P}(\mathrm{observation} \mid \mathrm{class}) = \prod_{i=1}^{n} \mathsf{P}(\mathrm{feature}_i \mid \mathrm{class}),$$
where $n$ is the total number of features describing a given
observation. Thus, $\mathsf{P}(\mathrm{class}|\mathrm{observation})$ now
can be calculated as

$$\mathsf{P}(\mathrm{class} \mid \mathrm{\mathrm{observation}}) = \mathsf{P}(\mathrm{class})\times \prod_{i=1}^{n}\frac{\mathsf{P}(\mathrm{feature}_i\mid \mathrm{class})}{\mathsf{P}(\mathrm{feature}_i)}\tag{1}$$

All the terms on the right-hand side can be estimated from the data as
respective relative frequencies;

## Data description

Our variant is: 27 mod 5 = 2.

-   **2 - fake news** This data set contains data of American news: a
    headline and an abstract of the article. Each piece of news is
    classified as fake or credible. The task is to classify the news
    from test.csv as credible or fake.

```{r}
# here goes a list of libraries that we used
library(tidytext)
library(readr)
library(dplyr)
library(ggplot2)
library(qdap)
```
    
### Data pre-processing

The only data that is pre-processed are the paths to csv files, all other data is processed inside the classifier.

```{r}
test_path <- "test.csv"
train_path <- "train.csv"

stop_words <- read_file("stop_words.txt")
splitted_stop_words <- strsplit(stop_words, split='\n')
splitted_stop_words <- splitted_stop_words[[1]]
```

## Classifier implementation

Naive Bayes classifier that is created to analyse text of train data and to use it for future predictions. Is is based on applying Bayes theorem with independence assumptions between the features. In our case we determine if the given text can be determined as fake news or credible news. At first we train our classifier with big csv table that contains more than 3000 entries of different news with labels that classify them. We create data frame with probabilities of words to be in given category, which will be used in next functions.

Function predict is the most important function in classifier. It returns suggestion if the text that was given is fake (FALSE) or credible (TRUE). That is calculated with use of modified Bayes theorem. In our case we have to evade continious multiplying by values that are less than 1, because it can lead to unpredicted result, as our variable can become 0 due to limitation of computer. That's why we would multiply our constant by probability of word given that we look for it in credible words and divide it by probability of word, given that we look for it in fake words and vice versa. In the end we just find what value is bigger and that is our choice for prediction.


```{r}
naiveBayes <- setRefClass("naiveBayes",
                          
# here it would be wise to have some vars to store intermediate result
# frequency dict etc. Though pay attention to bag of words! 
fields = list(
  fake_data = "data.frame", credible_data = "data.frame", all_data = "data.frame",
  all_counter = "numeric", fake_counter = "numeric", credible_counter = "numeric"
),


methods = list(
  
  # prepare your training data as X - bag of words for each of your
  # messages and corresponding label for the message encoded as 0 or 1 
  # (binary classification task)
  fit = function(data_path)
  {
    # Stop words
    stop_words <- read_file("stop_words.txt")
    splitted_stop_words <- strsplit(stop_words, split='\n')
    splitted_stop_words <- splitted_stop_words[[1]]
    
    # Read file for training
    data_file <- read.csv(file = data_path, stringsAsFactors = FALSE)
    
    # Number of all words
    all_counter <<- sum((unnest_tokens(data_file, 'splitted', 'Body', token="words", to_lower = TRUE) %>% filter(!splitted %in% splitted_stop_words) %>% count(splitted,sort=TRUE))[2])
    
    # Create two data frames that have credible and fake news
    data_fake <- data_file[!(data_file$Label=="credible"),]
    data_credible <- data_file[!(data_file$Label=="fake"),]
    
    # Tokenise fake news and find probabilities of each word given that news are fake
    fake_tokens <- unnest_tokens(data_fake, 'splitted', 'Body', token="words", to_lower = TRUE) %>% filter(!splitted %in% splitted_stop_words)
    fake_counters <- fake_tokens %>% count(splitted,sort=TRUE)
    
    summa <- sum(fake_counters[2])
    fake_counter <<- summa
    
    unique_values <- nrow(fake_counters)
    
    fake_probability <- fake_counters
    
    for (x in 1:unique_values){
      fake_probability[x, 2] <- (fake_probability[x, 2] + 1) / (summa + unique_values)
    }
    
    #fake_data <<- fake_counters
    fake_data <<- fake_probability
    
    # Tokenise credible news and find probabilities of each word given that news are fake
    credible_tokens <- unnest_tokens(data_credible, 'splitted', 'Body', token="words", to_lower = TRUE) %>% filter(!splitted %in% splitted_stop_words)
    credible_counters <- credible_tokens %>% count(splitted,sort=TRUE)
    
    summa <- sum(credible_counters[2])
    credible_counter <<- summa
    
    unique_values <- nrow(credible_counters)
    
    credible_probability <- credible_counters
    
    for (x in 1:unique_values){
      credible_probability[x, 2] <- (credible_probability[x, 2] + 1) / (summa + unique_values)
    }
    
    #credible_data <<- credible_counters
    credible_data <<- credible_probability
    
    print("MODEL IS FITTED")
  },
  
  # return prediction for a single message 
  predict = function(message)
  {
    fake_probability_overall = fake_counter / all_counter
    credible_probability_overall = credible_counter / all_counter
    
    # Take message and split it while deleting stop words from it
    message <- tolower(message)
    words <- strsplit(message , split = " ")[[1]] 
    words <- words[!words %in% splitted_stop_words]
    
    # Checks conditional probability for fake news
    fake_probability = 1
    
    for (word in words){
      if (word %in% fake_data$splitted & word %in% credible_data$splitted){
        fake_probability = fake_probability * fake_data[which(fake_data[1] == word), 2] / credible_data[which(credible_data[1] == word), 2]
      }
      else {
        fake_probability = fake_probability * (1/fake_counter) /(1/all_counter)
      }
    }
    
    # Checks conditional probability for credible news
    credible_probability = 1
    
    for (word in words){
      if (word %in% credible_data$splitted & word %in% fake_data$splitted){
        credible_probability = credible_probability / fake_data[which(fake_data[1] == word), 2] * credible_data[which(credible_data[1] == word), 2]
      }
      else {
        credible_probability = credible_probability * (1/credible_counter) /(1/all_counter)
      }
    }
    # Returns if that message is fake (FALSE) or credible (TRUE)
    if (fake_probability >= credible_probability){
      return (FALSE)
    }
    else{
      return (TRUE)
    }
  },
  
  # score you test set so to get the understanding how well you model
  # works.
  # look at f1 score or precision and recall
  # visualize them 
  # try how well your model generalizes to real world data! 
  score = function(data_path)
  {
    # Read file with real world data
    data_file <- read.csv(file = data_path, stringsAsFactors = FALSE)
    
    # Initialize counters for guesses
    correct_guesses = 0
    correct_credibles = 0
    correct_fakes = 0
    wrong_credibles = 0
    wrong_fakes = 0
    wrong_guesses = 0
    
    # For loop through all rows in data frame of real world data
    for (row in 1:nrow(data_file)){
      result <- model$predict(data_file[row, 3])
      if (result == TRUE & data_file[row, 4] == "credible"){
        correct_guesses = correct_guesses + 1
        correct_credibles = correct_credibles + 1
      }
      else if(result == FALSE & data_file[row, 4] == "fake"){
        correct_guesses = correct_guesses + 1
        correct_fakes = correct_fakes + 1
      }
      else if (result == TRUE){
        wrong_credibles = wrong_credibles + 1
        wrong_guesses = wrong_guesses + 1
      }
      else{
        wrong_fakes = wrong_fakes + 1
        wrong_guesses = wrong_guesses + 1
      }
    }
    print("Accuracy of model is:")
    print(correct_guesses/(correct_guesses + wrong_guesses))
    print("Precision of credible is")
    print(correct_credibles / (correct_credibles + wrong_credibles))
    print("Precision of fakes is ")
    print(correct_fakes / (correct_fakes + wrong_fakes))
        wrong_fake_probability <- wrong_fakes / (correct_guesses + wrong_guesses)
    wrong_credible_probability <- wrong_credibles / (correct_guesses + wrong_guesses)
    data <- as.matrix(data.frame(Total = c(correct_guesses/(correct_guesses + wrong_guesses), 1-correct_guesses/(correct_guesses + wrong_guesses)),
                                Credible = c(correct_credibles / (correct_credibles + wrong_credibles), 1 - correct_credibles / (correct_credibles + wrong_credibles)),
                                  Fake = c(correct_fakes / (correct_fakes + wrong_fakes), 1 - correct_fakes / (correct_fakes + wrong_fakes))))
    rownames(data) <- c("Correct guess", "Wrong guess")
    barplot(data,
            col = c("#1b98e0", "#353436"),
            beside = TRUE)
    legend("center",
           legend = c("Credible", "Fake"),
           fill = c("#1b98e0", "#353436"))
    
    precision_credible <- correct_credibles / (correct_credibles + wrong_credibles)
    recall_credible <- correct_credibles / (correct_credibles + wrong_fakes)
    precision_fake <- correct_fakes / (correct_fakes + wrong_fakes)
    recall_fake <- correct_fakes / (correct_fakes + wrong_credibles)
    f1score_credible <- 2 * precision_credible * recall_credible / (precision_credible + recall_credible)
    f1score_fake <- 2 * precision_fake * recall_fake / (precision_fake + recall_fake)
    
    data <- as.matrix(data.frame(Precision = c(precision_credible, precision_fake),
                                 Recall = c(recall_credible, recall_fake),
                                  F1Score = c(f1score_credible, f1score_fake)))
                                  
    rownames(data) <- c("Credible", "Fake")
    barplot(data,
            col = c("#1b98e0", "#353436"),
            beside = TRUE)
    legend("center",
           legend = c("Credible", "Fake"),
           fill = c("#1b98e0", "#353436"))
  }
))

model = naiveBayes()
model$fit(train_path)
```

## Measure effectiveness of your classifier

- Making classifier isn't the end of the process, we should measure effectiveness of it. Good measurement of it is F1Score, that uses precision and recall to get the score of effectiveness of classifier. To calculate it we can use following formula: 2 * Precision * Recall / (Precision + Recall). For that we run function score that will run test data set for our classifier.

```{r}
model$score(test_path)
```


### Data visualization

Each time you work with some data, you need to understand it before you
start processing it. R has very powerful tools to make nice plots and
visualization. Show what are the most common words for negative and
positive examples as a histogram, word cloud etc. Be creative!
=

```{r}
# Read file to plot most frequent words from fake news
data <- read.csv(file = test_path, stringsAsFactors = FALSE)

# Split data into two sets (fake and credible news)
data_fake <- data[!(data$Label=="credible"),]
data_credible <- data[!(data$Label=="fake"),]

# Text, that is classified as fake, without stop words
data_fake <- unnest_tokens(data_fake, 'splitted', 'Body', token="words", to_lower = TRUE) %>% filter(!splitted %in% splitted_stop_words)

# Plot of words in fake news
print("WORDS THAT APPEAR IN FAKE NEWS")
frequent_terms <- freq_terms(data_fake[4], 20)
plot(frequent_terms, xlab=c(0,20), ylab=c(0,20))

```

Some text


```{r}

# Text, that is classified as fake, without stop words
data_credible <- unnest_tokens(data_credible, 'splitted', 'Body', token="words", to_lower = TRUE) %>% filter(!splitted %in% splitted_stop_words)

# Plot of words in fake news
print("WORDS THAT APPEAR IN CREDIBLE NEWS")
frequent_terms <- freq_terms(data_credible[4], 20)
plot(frequent_terms, xlab=c(0,20), ylab=c(0,20))
```

## Conclusions

 - To perform this task, we used the Naive Bayes Classifier. The algorithm is based on the Bayes theorem and predicts the tag of a text such as a piece of email or newspaper article. It calculates the probability of each tag for a given sample and then gives the tag with the highest probability as output. This means we find the probability of every occurrence of a certain word in the false or credible news. This approach is great and highly scalable and can easily handle large datasets, but it's not perfect, still we have errors, becouse Conditional Independence Assumption does not always hold. In most situations, the feature shows some form of dependency.

 - Due to the large dataset our algorithm works better than it would work with smaller datasets.
 - Besides, here we learned how to work with the R language, which will help us in the future research.
